model_path: "EleutherAI/pythia-160m-deduped"
tokenizer_path: "EleutherAI/gpt-neox-20b"
save_dir: "/mnt/nvme/home/alex/repos/rlhf/ckpts/160M-sft-IHP"

train_args:
  output_dir: "/mnt/nvme/home/alex/repos/rlhf/ckpts/160M-sft-IHP"
  num_train_epochs: 1
  logging_steps: 100
  save_strategy: "no"
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  warmup_steps: 100
  weight_decay: 0.01
  learning_rate: 1.0e-5
  save_total_limit: 1
  logging_dir: "./logs"
  fp16: True
  evaluation_strategy: "epoch"

data_path: "Dahoas/instruct_helpful_preferences"
trainer: "masked"